{"cells":[{"cell_type":"markdown","metadata":{"id":"7BxdS3wjgulL"},"source":["# 7.01\n"]},{"cell_type":"markdown","metadata":{"id":"1HVP8DBr8-AL"},"source":["# Loading libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQDtuTpIgulR"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","pd.set_option('display.max_columns', None)\n"]},{"cell_type":"markdown","metadata":{"id":"V5Agqawp9Bx1"},"source":["# Reading data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11024,"status":"ok","timestamp":1690200022166,"user":{"displayName":"Ignacio Soteras","userId":"02050793736257155229"},"user_tz":-120},"id":"B9-PcfNB5K4d","outputId":"994ee9ad-1824-4424-e82f-5103e84eb039"},"outputs":[],"source":["data = pd.read_csv('learningSet.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1690200022167,"user":{"displayName":"Ignacio Soteras","userId":"02050793736257155229"},"user_tz":-120},"id":"IhIQGVCo45Gf","outputId":"196113d2-b480-4867-bf32-b12a2e4a4033"},"outputs":[],"source":["print(data.shape)\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Column \"TARGET_B\" encodes if the customer answered or not the call"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['TARGET_B'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["Column \"TARGET_D\" provide the donation amount."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['TARGET_D'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data[data['TARGET_B']>0]['TARGET_D'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["To solve this problem we will first build a classification model to predict who will more likely respond and then for those respondents, we will build a regression model to predict the donation amount.\n","\n","Then we can use the cost matrix to calculate the total benefit from the donations (remember that the company has to do a mailing champaing and each envelope costs some money).\n","\n","Some of the challenges with the dataset are as follows:\n","\n","* Large number of features: The data set has over 450 features. Hence selecting the right features for the model is very critical and at the same time it is not easy as the same traditional ways of removing features is not effective given the large number of features. Apart from feature selection, feature extraction (creating your own features using the existing features) is also not easy in this case.\n","\n","* Sparsity of the dataset: There are a lot of features with a large number of null values.\n","\n","* Data imbalance: For developing a classification, there is a huge imbalance in the training dataset with only approximately 5000 values for one category as compared to cover 95,000 instances for the other category."]},{"cell_type":"markdown","metadata":{},"source":["# Review data cleaning process"]},{"cell_type":"markdown","metadata":{},"source":["There are a lot of columns that have a very high percentage of null values. It is a highly sparse dataset.\n","We can decide on a threshold and then remove those variables. There is no rule of thumb to decide on this threshold value.\n","Sometimes it can as low as 25%-30%. And sometimes in some data sets you might find that even though there are more than 50% missing values in a column, you might have to include that variable in your analysis.\n","A lot of it depends on the business context as well. In this case we will take this threshold to be 25% and then check the definitions of the columns filtered, to see if there is any column that we might want to keep."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nulls_percent_df = pd.DataFrame(data.isna().sum()/len(data)).reset_index()\n","nulls_percent_df.columns = ['column_name', 'nulls_percentage']\n","nulls_percent_df"]},{"cell_type":"markdown","metadata":{},"source":["Which columns have NA's?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nulls_percent_df[nulls_percent_df['nulls_percentage']!=0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["columns_above_threshold = nulls_percent_df[nulls_percent_df['nulls_percentage']>0.25]\n","columns_above_threshold['column_name']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["drop_columns_list = list(columns_above_threshold['column_name'])\n","print(drop_columns_list)"]},{"cell_type":"markdown","metadata":{},"source":["From the list above that includes the columns that have over 25% null values, you discussed with your manager you were told that the following columns are important -> **wealth1, wealth2**\n","We will remove these variables from the above list\n","RDATE3, RAMNT_3 are important but they have too many null values"]},{"cell_type":"markdown","metadata":{},"source":["# Activity\n","\n","Create a function that takes a dataframe as an input and a percentual threshold (default value = 0.25) and returns a list of columns with null values greater than the specified threshold"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the function here\n","def null_percent_col_list (df, threshold:float = 0.25)-> list:\n","    df2 = df.copy()\n","    nulls_percent_df = pd.DataFrame(df2.isna().sum()/len(df2)).reset_index()\n","    nulls_percent_df.columns = ['column_name', 'nulls_percentage']\n","    columns_above_threshold = nulls_percent_df[nulls_percent_df['nulls_percentage']>threshold]['column_name'].tolist()\n","    #columns_above_threshold =[columns_above_threshold]\n","    return columns_above_threshold\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use your function here\n","cols_to_drop = null_percent_col_list(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(cols_to_drop)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(cols_to_drop)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# End of the activity"]},{"cell_type":"markdown","metadata":{},"source":["# More data cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that there are a lot of columns that have blank spaces which represent no value in this case.\n","They were not identified as null values by python as they are empty spaces that are read as character values by\n","python. We will replace those values by NaNs and repeat the analysis\n","\n","Before we do that we will replace the blank values from the column \"MAILCODE\" by \"A\" which would mean the address is okay (pl check the definition of the variable in the description)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['MAILCODE'].value_counts(dropna=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['MAILCODE'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['MAILCODE'] = data['MAILCODE'].apply(lambda x: x.replace(\" \", \"A\"))\n","#data['MAILCODE'] = np.where(data['MAILCODE'] == \" \", \"A\",data['MAILCODE'] )\n","#data['MAILCODE'] = data['MAILCODE'].apply(lambda x: x if (x != \" \") else \"A\")\n","# function(arg1)\n","#df[col] = list(map(function,df[col]))\n","# function(arg1, arg2, arg3)\n","#df[col] = list(map(function,df[col],[arg2]*len(df), [arg3]*len(df)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Now we can replace the rest space characters with np.NaN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = data.apply(lambda x: x.replace(\" \", np.NaN))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Activity\n","\n","Use the previous function to obtain the columns with null values greater than 0.25 and store those columns in a list called \"drop_columns_list\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","drop_columns_list = null_percent_col_list(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["drop_columns_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(drop_columns_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# End of activity"]},{"cell_type":"markdown","metadata":{},"source":["We would again repeat the same exercise as the last time. We will discuss it with the team, manager, and/or other stakeholders to see which columns we need to retain here.\n","\n","Like the last time we will keep the following columns. **wealth1, wealth2 along with these VETERANS, SOLIH**\n","\n","Remove those column's names from the list of columns to drop."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def remove_columns(df, thr = 0.25, blacklist=None):\n","    ...\n","    if ( blacklist != None):\n","        drop_columns_list = [ col for col in drop_columns_list if col not in blacklist ]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["drop_columns_list = [ col for col in drop_columns_list if col not in ['WEALTH1','WEALTH2','VETERANS','SOLIH'] ]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(drop_columns_list)"]},{"cell_type":"markdown","metadata":{},"source":["# X-y split"]},{"cell_type":"markdown","metadata":{},"source":["Since we have a huge number of features, it would be easier to work independently on numerical features and categorical features.\n","\n","For the target variables, for now we will retain them both together. But later, we will build a classification model first where we would need the column TARGET_B only."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.TARGET_B.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y = data[['TARGET_B', 'TARGET_D']]\n","Y.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["numerical = data.select_dtypes(np.number)\n","numerical = numerical.drop(columns = ['TARGET_B', 'TARGET_D'])\n","numerical.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["numerical.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorical = data.select_dtypes([object])\n","categorical.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorical.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Working with categorical columns"]},{"cell_type":"markdown","metadata":{},"source":["We will work with the categorical features first. Look at the columns one by one. Some of the operations which we will perform are:\n","\n","- Replace null values with the most occurring categories\n","- Reduce the number of categories in a column by grouping\n","\n","It is important to note that some columns are defined by python as categorical/object types. There might be other columns defined as numerical that we want as categorical. We will look them later when we were working on numerical types."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorical.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["# Categorical Variables"]},{"cell_type":"markdown","metadata":{},"source":["Here we will try to reduce the number of categories. An ideal way would have been to group the states into\n","regions. But in this case we will group all the states with counts less than 2500 into one category \"other\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(categorical['STATE'].value_counts()).reset_index()\n","\n","\n","df.columns = ['state', 'count']\n","other_states = list(df[df['count']<2500]['state'])\n","\n","# other_states = ['CA','AR','MD']\n","def clean_state(x):\n","    if x in other_states:\n","        return 'other'\n","    else:\n","        return x\n","\n","# clean_states(x,other_states) for x, other_states in zip(categorical['STATE'].values,other_states)\n","categorical['STATE'] = list(map(clean_state, categorical['STATE']))\n","#categorical['STATE'] = categorical['STATE'].apply(clean_state)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(categorical['STATE'].nunique())\n","categorical['STATE'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["# 7.01 Lab | Revisiting Machine Learning Case Study"]},{"cell_type":"markdown","metadata":{},"source":["Lab instructions can be found [here](https://github.com/isg75/lab-revisiting-machine-learning/tree/master)"]},{"cell_type":"markdown","metadata":{},"source":["# Lab | Revisiting Machine Learning Case Study\n","\n","- In this lab, you will use `learningSet.csv` file which we used during the class. \n","\n","### Instructions\n","\n","Complete the following steps on the categorical columns in the dataset:\n","\n","- Check for null values in all the columns\n","- Create a new empty list called `drop_list`. We will append to this list a set of columns to be dropped later. Add the following columns to this:\n","    - `OSOURCE` - symbol definitions not provided, too many categories\n","    - `ZIP` - we are including states already\n","- Identify columns that have over 85% missing values and add them to the previous list.\n","- Remove the columns included in the `drop_list` from the dataframe\n","- Now, reduce the number of categories in the column `GENDER`. The column should only have either \"M\" for males, \"F\" for females, and \"other\" for all the rest\n","    - Note that there are a few null values in the column. We will first replace those null values using the code below:\n","\n","    ```python\n","    print(categorical['GENDER'].value_counts())\n","    categorical['GENDER'] = categorical['GENDER'].fillna('F')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":833,"status":"ok","timestamp":1690200022991,"user":{"displayName":"Ignacio Soteras","userId":"02050793736257155229"},"user_tz":-120},"id":"ch4kkMnKgulS","outputId":"9c00f0de-f683-4f1f-ee5b-c952c481f26a"},"outputs":[],"source":["# Check for null values in all the columns\n","categorical.isnull().sum()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a new empty list called `drop_list`. We will append to this list a set of columns to be dropped later. Add the following columns to this:\n","#    - `OSOURCE` - symbol definitions not provided, too many categories\n","#    - `ZIP` - we are including states already\n","drop_list = []\n","[drop_list.append(x)for x in ['OSOURCE', 'ZIP']]\n","#drop_list.append('ZIP')\n","drop_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  Identify columns that have over 85% missing values and add them to the previous list.\n","\n","columns_above_85 = null_percent_col_list(categorical, 0.85)\n","display(len(columns_above_85))\n","\n","#'OSOURCE' in columns_above_threshold\n","#'ZIP' in columns_above_threshold\n","drop_list = [x for x in drop_list if x not in columns_above_85] + columns_above_85\n","drop_list\n","len(drop_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["drop_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  Remove the columns included in the `drop_list` from the dataframe\n","categorical = categorical.drop(columns = drop_list) \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorical"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# - Now, reduce the number of categories in the column `GENDER`. The column should only have either \"M\" for males, \"F\" for females, and \"other\" for all the rest\n","#    - Note that there are a few null values in the column. We will first replace those null values using the code below:\n","#    ```python\n","#    print(categorical['GENDER'].value_counts())\n","#    categorical['GENDER'] = categorical['GENDER'].fillna('F')\n","\n","display(categorical.GENDER.isnull().sum())\n","display(categorical.GENDER.value_counts(dropna=False))\n","display(categorical.GENDER.unique())\n","categorical['GENDER'] = categorical['GENDER'].fillna('F')\n","categorical[\"GENDER\"] = categorical[\"GENDER\"].apply(lambda x: x if x in ['F', \"M\"] else 'other')\n","display(categorical.GENDER.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorical.columns"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
